{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNi5unIhk96GtyDzyeMHFlG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HazSyl1/GPT-From-Scratch/blob/main/llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRRwV45g4Z0z",
        "outputId": "1057a6d8-d61c-4818-92b6-228559742355"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-06 12:52:23--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-02-06 12:52:23 (21.8 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt') as f:\n",
        "  text=f.read()"
      ],
      "metadata": {
        "id": "gx71F7Og9LFm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of file:{len(text):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyKGoB4f9X-l",
        "outputId": "2accbc39-a99b-4a23-8632-a344701f4be0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of file:1,115,394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnt3abM23s9I",
        "outputId": "bef9a43f-b553-4197-beea-89f683efacdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars=sorted(list(set(text)))\n",
        "vocab_size=len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "EY4CCHgo4vkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bcc1e66-99dc-48d5-ed0c-c3e2d5b69802"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizing . Character lvl\n",
        "st_to_i={ch:i for i,ch in enumerate(chars)}\n",
        "i_to_st={i:ch for i,ch in enumerate(chars)}\n",
        "enc=lambda s: [st_to_i[c] for c in s]\n",
        "dec=lambda l:''.join([i_to_st[i] for i in l])\n",
        "\n",
        "print(\"hii there\")\n",
        "print(\"Encoding:\",enc(\"hii there\"))\n",
        "print(\"Decoder:\",dec(enc(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSViSA0OQiyj",
        "outputId": "21d0b2ee-9edf-4f98-99e6-7f2c76050e2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hii there\n",
            "Encoding: [46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "Decoder: hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj8sIjUkBDOg",
        "outputId": "4aa2ca60-6e66-4653-969a-397137b5478d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##TIKTOKEN\n",
        "# !pip install tiktoken\n",
        "import tiktoken\n",
        "en=tiktoken.get_encoding('gpt2')\n",
        "x=en.encode(\"hii there\")\n",
        "y=en.decode(x)\n",
        "print(\"Encoded:\",x)\n",
        "print(\"Decoded:\",y)\n",
        "print(\"Vocab Len\",en.n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIKU1Dxy4ZVH",
        "outputId": "4e4e21ee-4d15-4c88-cb66-580f6fbf2dd8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: [71, 4178, 612]\n",
            "Decoded: hii there\n",
            "Vocab Len 50257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encode entire text in a tensor\n",
        "import torch\n",
        "data=torch.tensor(enc(text),dtype=torch.long)\n",
        "print(data.shape,data.dtype)\n",
        "print(data.size())\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5pi_Iihou4J",
        "outputId": "22116bca-abeb-4564-9ca3-8785f4ff2b1e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "torch.Size([1115394])\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Spliting\n",
        "n=int(0.9*len(data))\n",
        "train_data=data[:n]\n",
        "val_data=data[n:]"
      ],
      "metadata": {
        "id": "JSx2Ug3Y4t_j"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YveYPxFLqHjL",
        "outputId": "97f0c2df-200e-47c2-c838-5107ac75a541"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=train_data[:block_size]\n",
        "y=train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "  context=x[:t+1]\n",
        "  target=y[t]\n",
        "  print(f\"When input is {context} , the target is {target}\")"
      ],
      "metadata": {
        "id": "N5V2nMvX5rHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aec2980-978a-41c4-a347-bf2dcb4dcf79"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When input is tensor([18]) , the target is 47\n",
            "When input is tensor([18, 47]) , the target is 56\n",
            "When input is tensor([18, 47, 56]) , the target is 57\n",
            "When input is tensor([18, 47, 56, 57]) , the target is 58\n",
            "When input is tensor([18, 47, 56, 57, 58]) , the target is 1\n",
            "When input is tensor([18, 47, 56, 57, 58,  1]) , the target is 15\n",
            "When input is tensor([18, 47, 56, 57, 58,  1, 15]) , the target is 47\n",
            "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) , the target is 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size=4#how many independant sequences will be processed in parallel...\n",
        "block_size=8#what  is the max context length for predictions....\n",
        "\n",
        "def get_batch(split):\n",
        "  data=train_data if split=='train' else val_data\n",
        "  ix=torch.randint(len(data)-block_size, (batch_size,)) #batch_size number of random offsets b/w 0 to len(data)-block_size\n",
        "  #print(f\"{ix}:\\n\")\n",
        "  x=torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y=torch.stack([data[i+1:1+i+block_size] for i in ix])\n",
        "  return x,y\n",
        "\n",
        "xb,yb=get_batch('train')\n",
        "print('Inputs:')\n",
        "print(xb.shape)\n",
        "print(xb ,\"\\n\")\n",
        "print(\"Targets:\")\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "print(\"___________\")\n",
        "\n",
        "for b in range(batch_size): #batch dim\n",
        "  for t in range(block_size):#time dim\n",
        "    context=xb[b, :t+1]\n",
        "    target=yb[b,t]\n",
        "    print(f\"When input is: {context} , target is : {target}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu4jptaTrz_5",
        "outputId": "9db1af46-c8e2-47d2-c2e3-f4aa4dced783"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]]) \n",
            "\n",
            "Targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "___________\n",
            "When input is: tensor([24]) , target is : 43\n",
            "When input is: tensor([24, 43]) , target is : 58\n",
            "When input is: tensor([24, 43, 58]) , target is : 5\n",
            "When input is: tensor([24, 43, 58,  5]) , target is : 57\n",
            "When input is: tensor([24, 43, 58,  5, 57]) , target is : 1\n",
            "When input is: tensor([24, 43, 58,  5, 57,  1]) , target is : 46\n",
            "When input is: tensor([24, 43, 58,  5, 57,  1, 46]) , target is : 43\n",
            "When input is: tensor([24, 43, 58,  5, 57,  1, 46, 43]) , target is : 39\n",
            "When input is: tensor([44]) , target is : 53\n",
            "When input is: tensor([44, 53]) , target is : 56\n",
            "When input is: tensor([44, 53, 56]) , target is : 1\n",
            "When input is: tensor([44, 53, 56,  1]) , target is : 58\n",
            "When input is: tensor([44, 53, 56,  1, 58]) , target is : 46\n",
            "When input is: tensor([44, 53, 56,  1, 58, 46]) , target is : 39\n",
            "When input is: tensor([44, 53, 56,  1, 58, 46, 39]) , target is : 58\n",
            "When input is: tensor([44, 53, 56,  1, 58, 46, 39, 58]) , target is : 1\n",
            "When input is: tensor([52]) , target is : 58\n",
            "When input is: tensor([52, 58]) , target is : 1\n",
            "When input is: tensor([52, 58,  1]) , target is : 58\n",
            "When input is: tensor([52, 58,  1, 58]) , target is : 46\n",
            "When input is: tensor([52, 58,  1, 58, 46]) , target is : 39\n",
            "When input is: tensor([52, 58,  1, 58, 46, 39]) , target is : 58\n",
            "When input is: tensor([52, 58,  1, 58, 46, 39, 58]) , target is : 1\n",
            "When input is: tensor([52, 58,  1, 58, 46, 39, 58,  1]) , target is : 46\n",
            "When input is: tensor([25]) , target is : 17\n",
            "When input is: tensor([25, 17]) , target is : 27\n",
            "When input is: tensor([25, 17, 27]) , target is : 10\n",
            "When input is: tensor([25, 17, 27, 10]) , target is : 0\n",
            "When input is: tensor([25, 17, 27, 10,  0]) , target is : 21\n",
            "When input is: tensor([25, 17, 27, 10,  0, 21]) , target is : 1\n",
            "When input is: tensor([25, 17, 27, 10,  0, 21,  1]) , target is : 54\n",
            "When input is: tensor([25, 17, 27, 10,  0, 21,  1, 54]) , target is : 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self ,vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table=nn.Embedding(vocab_size,vocab_size)\n",
        "\n",
        "  def forward(self,idx,targets=None):\n",
        "    logits=self.token_embedding_table(idx) #(B,T,C: Batch , Time , Channel)(4,8,65[vocab_size])\n",
        "    #BUT pytorch expects , B ,C,T . so we re shape\n",
        "    if targets ==None:\n",
        "      loss=None\n",
        "    else:\n",
        "      B,T,C=logits.shape\n",
        "      logits=logits.view(B*T,C)\n",
        "      targets=targets.view(B*T) #or -1 , cause pytorch can figure that by itself\n",
        "      loss=F.cross_entropy(logits,targets)\n",
        "\n",
        "    return logits,loss\n",
        "\n",
        "  def generate(self,idx,max_new_tokens):\n",
        "    #idx is (B,T)\n",
        "    for _ in range(max_new_tokens):\n",
        "      logits,loss=self(idx)\n",
        "      logits=logits[:,-1,:] #becomes (B,C) #Pluck out the last element int he TIme dimension,because those are the prediction of what comes next\n",
        "      #print(\"LL\",logits.shape)\n",
        "      probs=F.softmax(logits,dim=-1) #(B,C)\n",
        "\n",
        "      idx_next=torch.multinomial(probs,num_samples=1) #(B,1)\n",
        "      idx=torch.cat((idx,idx_next),dim=1)#(B,T+1)\n",
        "    return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits,loss = m(xb,yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(dec(m.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AmUVuVJuIU-",
        "outputId": "ac8d93cb-8db1-4bd1-a5ef-c7032e18e19e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(5.0364, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "l-QYjt'CL?jLDuQcLzy'RIo;'KdhpV\n",
            "vLixa,nswYZwLEPS'ptIZqOZJ$CA$zy-QTkeMk x.gQSFCLg!iW3fO!3DGXAqTsq3pdgq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=torch.optim.Adam(m.parameters(),lr=1e-3)"
      ],
      "metadata": {
        "id": "PZTdqjdoxwx2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "for steps in range(10000):\n",
        "  xb,yb=get_batch('train')\n",
        "\n",
        "  logits,loss=m(xb,yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgikpQz1xwzv",
        "outputId": "62e8e1a4-82cb-4ad3-8c29-f5b60bce54be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.559103012084961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dec(m.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_tokens=400)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgK5U5x6EnKk",
        "outputId": "86947bf5-2ecb-474e-dd22-7c6afeb1cdf4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ong h hasbe pave pirance\n",
            "RDe hicomyonthar's\n",
            "PES:\n",
            "AKEd ith henourzincenonthioneir thondy, y heltieiengerofo'dsssit ey\n",
            "KINld pe wither vouprrouthercckehathe; d!\n",
            "My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so itJas\n",
            "Waketancothanan hay.JUCLUKILe, bs, r loncave w hollular s O:\n",
            "HIs; ht anjx?\n",
            "\n",
            "DUThineent.\n",
            "\n",
            "LaZEESTEORDY:\n",
            "h l.\n",
            "KEONGBUCHandspo be y,-JZNEEYowddy scace, tridesar, wne'shenous s \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-lXp0pHiGOjo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Math Trick in self-attention"
      ],
      "metadata": {
        "id": "08IoElLdg7dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C =4,8,2\n",
        "x=torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "id": "svZYKwhYBKq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d777867-7fa2-4ef5-eb71-760e2fd8da42"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Info should only transfer from rpevious time stamp to current , casuse we're not aware of teh future lol\n",
        "#Say i'm at C=5 , I'd like to avg the 4,3,2,1 ,to get an average.\n",
        "#Now getting an avg is not really workfull , its shit , cause info gets lost. . . .\n",
        "#For every T token we'd like to ge the avg of all before it . . .  ."
      ],
      "metadata": {
        "id": "L9PB18AUBKuw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##VERSION1\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev=x[b,:t+1] #(t,C)\n",
        "    xbow[b,t]=torch.mean(xprev,0) #Avereging the t\n"
      ],
      "metadata": {
        "id": "jlyxHx0MBKzM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2OElJajmLz_",
        "outputId": "41ea9e15-a4db-4b0a-8165-4b2c5dde7720"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.3596, -0.9152],\n",
              "        [ 0.6258,  0.0255],\n",
              "        [ 0.9545,  0.0643],\n",
              "        [ 0.3612,  1.1679],\n",
              "        [-1.3499, -0.5102],\n",
              "        [ 0.2360, -0.2398],\n",
              "        [-0.9211,  1.5433]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGx_m8zwmNDg",
        "outputId": "83d765dc-a558-4878-ccde-1e0c163ca439"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### VERSION2\n",
        "wei=torch.tril(torch.ones(T,T))\n",
        "wei=wei/wei.sum(1,keepdim=True)\n",
        "xbow2=wei @ x #(T,T) @ (B,T,C) -----> (B,T,T) @ (B,T,C) -----> (B,T,C)\n",
        "torch.allclose(xbow,xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3RbE5kVqWW9",
        "outputId": "555e154c-77cb-4d3d-8498-7376168e937b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0] ,xbow2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33MhyYRTqWKi",
        "outputId": "f116397b-90d7-42a7-8ba9-6a75af691a05"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]),\n",
              " tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We were able to use matrix multiplication , to get the weighted sums . . ."
      ],
      "metadata": {
        "id": "9UYQQLxuqyuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fw1nlLTst3p",
        "outputId": "150e343a-0f4d-4737-9247-dbb0060f93ae"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhZeMiD4uI0i",
        "outputId": "3ad85ea5-18bb-4c79-b4f8-9d8e618194df"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei=torch.zeros((T,T))\n",
        "wei=wei.masked_fill(tril == 0,float('-inf'))\n",
        "wei=F.softmax(wei,dim=-1)\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56ih3ihuszyC",
        "outputId": "c9124fbf-9532-4745-98f5-dab1766fdf7e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## VERSION 3 : Use SOFTMAX\n",
        "tril=torch.tril(torch.ones(T,T))\n",
        "wei=torch.zeros((T,T))\n",
        "wei=wei.masked_fill(tril==0,float('-inf'))\n",
        "wei=F.softmax(wei,dim=-1)\n",
        "xbow3=wei @ x\n",
        "xbow3[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWRcUhPusQeo",
        "outputId": "7894502d-c08a-415b-f87b-b98310dadbb7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " torch.manual_seed(42)\n",
        "a=torch.tril(torch.ones(2,3))\n",
        "a=a/torch.sum(a,1,keepdim=True)\n",
        "b=torch.randint(0,10,(3,2)).float()\n",
        "c=a@b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('b=')\n",
        "print(b)\n",
        "print('\\nc=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EpPJvYxmPfp",
        "outputId": "e3954b11-4f40-409e-d25e-04ba71e3743a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000]])\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g5fnRpnmqPyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PGPAkih1qJeX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}